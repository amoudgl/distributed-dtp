################# META ####################
seed: 123
debug: false
data_dir: /home/amoudgl/Projects/data

################# DATA MODULE ####################
datamodule:
  _target_: target_prop.datasets.ImageNet32DataModule
  batch_size: 256
  num_workers: 1
  pin_memory: true
  shuffle: true
  train_transforms:
    _target_: torchvision.transforms.Compose
    transforms:
    - _target_: torchvision.transforms.RandomHorizontalFlip
      p: 0.5
    - _target_: torchvision.transforms.RandomCrop
      size: 32
      padding: 4
      padding_mode: edge
    - _target_: torchvision.transforms.ToTensor
    - _target_: target_prop.datasets.imagenet32_normalization
  val_transforms:
    _target_: torchvision.transforms.Compose
    transforms:
    - _target_: torchvision.transforms.RandomHorizontalFlip
      p: 0.5
    - _target_: torchvision.transforms.RandomCrop
      size: 32
      padding: 4
      padding_mode: edge
    - _target_: torchvision.transforms.ToTensor
    - _target_: target_prop.datasets.imagenet32_normalization
  test_transforms:
    _target_: torchvision.transforms.Compose
    transforms:
    - _target_: torchvision.transforms.ToTensor
    - _target_: target_prop.datasets.imagenet32_normalization

################# MODEL ####################
model:
  _target_: target_prop.models.LayerParallelDTP
  hparams:
    use_scheduler: true
    feedback_training_iterations:
    - 25
    - 35
    - 40
    - 60
    - 25
    noise:
    - 0.4
    - 0.4
    - 0.2
    - 0.2
    - 0.08
    beta: 0.7
    feedback_samples_per_iteration: 1
    early_stopping_patience: 0
    init_symetric_weights: false
    plot_every: 10000
    f_optim:
      _target_: torch.optim.SGD
      lr: 0.01
      weight_decay: 0.0001
      momentum: 0.9
    b_optim:
      _target_: torch.optim.SGD
      lr:
      - 0.0001
      - 0.00035
      - 0.008
      - 0.008
      - 0.18
      weight_decay: 0
      momentum: 0.9

################# NETWORK ####################
network:
  _target_: target_prop.networks.SimpleVGG
  hparams:
    channels:
    - 128
    - 128
    - 256
    - 256
    - 512
    activation:
      _target_: torch.nn.ELU

################# TRAINER ####################
trainer:
  _target_: target_prop.trainers.LayerParallelTrainer
  max_epochs: 90
  gpus: 6
  seed: ${seed}
  backend: gloo
  logger:
    _target_: pytorch_lightning.loggers.WandbLogger

################# SCHEDULER ####################
scheduler:
  lr_scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    T_max: 85
    eta_min: 1.0e-05
  interval: epoch
  frequency: 1
